---
title: "Empirical Summary Statistics"
format: gfm
jupyter: python3
execute: 
  warning: false
  error: false
---


```{python}
#| label: import-packages

from os.path import isfile
from os.path import splitext
import os
import numpy as np
from numpy import ma
import msprime
import rasterio
from rasterio.mask import mask
import allel
import scipy.stats as stats
import pandas as pd
import geopandas as gpd
import itertools
from math import radians
from sklearn.metrics.pairwise import haversine_distances
from sklearn import linear_model
from shapely.geometry import Point
from esda.moran import Moran
from libpysal.weights import Voronoi
import time
from scipy.interpolate import NearestNDInterpolator
import numba
import tracemalloc
from scipy.stats import entropy
import warnings
from matplotlib import pyplot as plt
```


```{python}
#| label: define-functions

def coords_to_sample_dict_empirical(raster, coordinates, individual_ids=None, vcf_path=None):
  # get the cell that each individual belongs to  
  ## I have to iterate through each locality to get the cell ID for each individual locality. Masking everything returns the cell IDs out of order.
  cell_list = []
  for xy in coordinates:
  
      # mask requires an iterable as input, so I just repeated the two Point geometries in a list. Mask returns a single value since they overlap in the same place
      pt2 = [Point(xy), Point(xy)]
      
      # mask the raster with the points
      out_image = mask(raster, pt2, nodata="nan", filled = False)

      # turn into 1D array
      oi_1d = out_image[0][0].ravel()

      # # get the indices of the locality and append
      cell_id = ma.nonzero(oi_1d)[0]    
      cell_list.append(cell_id)
  
  cell_id_array = np.concatenate(cell_list, axis = 0)

  # get the number of individuals to sample from the simulation
  pop_dict_simulation = {}
  for cid in np.unique(cell_id_array):
      num_inds = np.sum(cell_id_array == cid) 
      pop_dict_simulation[cid] = num_inds

  pop_dict_sim_long = {}
  unique_ids = np.unique(cell_id_array)
  for i in range(len(unique_ids)):
      cid = unique_ids[i]
      if i > 0:
          cid_prev = unique_ids[i - 1]
          last_ind_prev = pop_dict_sim_long[cid_prev][len(pop_dict_sim_long[cid_prev]) - 1]
          pop_dict_sim_long[cid] = np.array(range(last_ind_prev + 1, last_ind_prev + pop_dict_simulation[cid] + 1))
      else: 
          pop_dict_sim_long[cid] = np.array(range(pop_dict_simulation[cid]))
  
  if individual_ids is None:
      try:
          if vcf_path is not None:
              raise ValueError
      except ValueError:
          print("When a VCF path is provided, individual IDs corresponding to those in the VCF are expected. Please provide those IDs.")
  elif vcf_path is None:
      try:
          if individual_ids is not None:
              raise ValueError
      except ValueError:
          print("When individual IDs are provided, a VCF file is expected. Please provide a path to your VCF file.")
  else:
      pop_dict_empirical = None
  
  if individual_ids is not None and vcf_path is not None:
      
      # read in the vcf
      callset = allel.read_vcf(vcf_path)

      # get the indices of each individual in the vcf
      ind_indices = []
      for cid in individual_ids:
          index = list(callset["samples"]).index(cid) 
          ind_indices.append(index)

      ind_indices_array = np.array(ind_indices)
      

      # make each cell id a key and the individuals that belong to that cell id the values
      pop_dict_empirical = {}
      for cid in np.unique(cell_id_array):
          id_inds = np.where(cell_id_array ==cid) 
          id_ind_indices = ind_indices_array[id_inds]
          pop_dict_empirical[cid] = id_ind_indices
  else:
      pop_dict_empirical = None
  
  return pop_dict_simulation, pop_dict_sim_long, pop_dict_empirical

def admix_to_deme_dict(admix_rast_path, pops_dict):

  # read in admixture raster
  with rasterio.open(admix_rast_path, "r") as src:
      r=src.read()

  # unravel the raster into one dimension for indexing
  r_1d = r.ravel()

  admix_dict = {}
  for key in pops_dict:
      k = r_1d[key]
      if k in admix_dict.keys():
          admix_dict[k].append(key)
      else:
          admix_dict[k] = [key]

  return admix_dict

def max_thresh_from_coords(raster, coordinates):

  xy = [Point(xy) for xy in coordinates]
  # mask the raster, so only cells that the coordinates overlap are masked
  out_image = mask(raster, xy, nodata="nan", filled = False)

  # find the minimum value of the masked raster
  max_thresh = np.min(out_image[0])

  return max_thresh

def counts_from_vcf(vcf, pops_dict, pops_dict_admix, r2_thresh = 0.1): 

  callset = allel.read_vcf(vcf)

  # convert to allele counts and counts of the alternate allele
  gt = allel.GenotypeArray(callset["calldata/GT"])

  # get the allele counts matrix for all individuals
  gc = gt.count_alleles(max_allele = 1)

  # only retain segregating alleles
  is_seg = gc.is_segregating()
  gt_seg = gt.compress(is_seg, axis=0)
  gc_seg = gc.compress(is_seg)

  # alt allele counts matrix
  # needed for finding unlinked SNPs
  gn = gt_seg.to_n_alt(fill=-1)

  # filter for unlinked loci
  # locate unlinked SNPs
  loc_unlinked = allel.locate_unlinked(gn, threshold=r2_thresh)

  # select unlinked SNPs
  gc_unlinked = gc_seg[loc_unlinked]
  gt_unlinked = gt_seg[loc_unlinked]

  # remove singletons
  not_singleton = ~gc_unlinked.is_singleton(allele = 1)
  gc_unlinked = gc_unlinked[not_singleton]

  gc_unlinked_pops = None

  if pops_dict:
      gt_unlinked = gt_unlinked[not_singleton]
      gc_unlinked_pops = gt_unlinked.count_alleles_subpops(max_allele = 1, subpops = pops_dict)
  # create allele counts matrices for the admixture populations
  if pops_dict_admix is not None:
      admix_dict_inds = {}
      for key in pops_dict_admix:
          demes = pops_dict_admix[key]
          admix_dict_inds[key] = []
          for d in demes:
              # convert numpy array to list
              inds = pops_dict[d].tolist()
              admix_dict_inds[key].extend(inds)
              
  gc_unlinked_admix = gt_unlinked.count_alleles_subpops(max_allele = 1, subpops = admix_dict_inds)

  return gc_unlinked, gc_unlinked_pops, gc_unlinked_admix

def sampled_cells_to_coords(raster, coordinates):
    
  # get the population IDs
  ## I have to iterate through each locality to get the cell ID for each individual locality. Masking everything returns the cell IDs out of order.
  ## I'm creating a dictionary 
  cell_dict = {}
  for xy in coordinates:

      # mask requires an iterable as input, so I just repeated the two Point geometries in a list. Mask returns a single value since they overlap in the same place
      pt2 = [Point(xy), Point(xy)]
      
      # mask the raster with the points
      out_image = mask(raster, pt2, nodata="nan", filled = False)

      ###### GET CELL INDICES ######
      # turn into 1D array
      oi_1d = out_image[0][0].ravel()

      # # get the indices of the locality and append
      cell_id = ma.nonzero(oi_1d)[0][0] 

      ####### GET CELL COORDINATES #############
      # get the indicex of the locality
      cell_ind = [tuple(_) for _ in np.transpose(ma.nonzero(out_image[0][0]))]

      rows, cols = zip(*cell_ind)  # unzip the cell indices to separate row and col lists
      coords_tuple = rasterio.transform.xy(raster.transform, rows, cols)
      
      # I have to convert the x and y coords to a list instead of a tuple, because the transform.xy function returns a tuple where each long and lat is a single-value list, which makes indexing later convoluted.
      x = coords_tuple[0][0]
      y = coords_tuple[1][0]

      coords = [x, y]

      cell_dict[cell_id] = coords
      
  return cell_dict

def split_landscape_by_admix_pop(raster_path, coords, admix_id, outfile, band_index=1, mask_rast=False):
  # open the raster
  r = rasterio.open(raster_path)
  # read in the raster. This imports the raster as a numpy array
  r2 = r.read(band_index, masked=True)

  # get the x,y indices of the empirical sampled cells
  indices_x = []
  indices_y = []
  for xy in coords:
  
      # mask requires an iterable as input, so I just repeated the two Point geometries in a list. Mask returns a single value since they overlap in the same place
      pt2 = [Point(xy), Point(xy)]
      
      # mask the raster with the points
      out_image = mask(r, pt2, nodata="nan", filled = False)

      # oi first raster
      oi = out_image[0][0]

      # get the locality index
      indices_tup = ma.nonzero(oi)

      indices_x.append(indices_tup[0])
      indices_y.append(indices_tup[1])

  indices_x = np.concatenate(indices_x)
  indices_y = np.concatenate(indices_y)

  # get all of the x, y indices of the input raster
  r_x, r_y = np.indices(r.shape)

  interp = NearestNDInterpolator(list(zip(indices_x, indices_y)), admix_id)
  z = interp(r_x, r_y)

  # apply mask of the SDM landscape
  if mask_rast:
        z = ma.masked_array(z, r2.mask, fill_value=-9, dtype=float)

  # check to make sure the filepath contains the ".tif" suffix, then write the file out
  try: 
      root, ext = splitext(outfile)
      if ext != ".tif" or "~" in root:
          raise SyntaxError
      print(f"Landscape with K assignment categories written to {outfile}.")
  except SyntaxError:
      print("The outfile cannot use tilde (~) path expansion and must have a .tif extension.")

  
  with rasterio.open(
          outfile,
          mode="w",
          driver="GTiff",
          height=z.shape[0],
          width=z.shape[1],
          count=1,
          dtype=z.dtype,  
          crs=r.crs,
          transform=r.transform,
          nodata=-9
      ) as new_dataset:
          new_dataset.write(z, 1)
  


def calc_sumstats(counts_array, demes_coordinates, admix_dict=None, counts_array_demes=None, counts_array_admix=None, between_admix_pop_sumstats = False):    
  # calculate scaled Hill numbers of the SFS, using Isaac Overcast's approach
  def hill_number(freqs, order):
      if order == 0:
          return len(np.nonzero(freqs)[0])
      if order == 1:
          h1 = np.exp(entropy(freqs))
          return h1
      tot = float(np.sum(freqs))
      proportions = np.array(freqs[freqs > 0])/tot
      prop_order = proportions**order
      h2 = np.sum(prop_order)**(1/(1-order))
      return h2
  
  # get pairwise dxy for pops
  # deme IDs is a list of population IDs we want to calculate DXY and FST for.
  def calc_between_deme_diversity(deme_ids):
      
      dxy = []
      ## also get the names of each pop pair to identify the raw dxy
      dxy_name = []

      fst = []
      fst_name = []

      # I'm using the demes_coordinates dictionary to iterate through the population names, so I can be sure that the DXY distances match up with the geographic distances
      for ac_ind in list(itertools.combinations(deme_ids, 2)):
          ac1 = counts_array_demes[ac_ind[0]]
          ac2 = counts_array_demes[ac_ind[1]]
          
          d = np.nanmean(allel.mean_pairwise_difference_between(ac1, ac2))
          d_name = f"dxy_{ac_ind[0]}_{ac_ind[1]}"

          num, den = allel.hudson_fst(ac1, ac2)

          f = np.nansum(num) / np.nansum(den)
          f_name = f"fst_{ac_ind[0]}_{ac_ind[1]}"

          dxy.append(d)
          dxy_name.append(d_name)
          fst.append(f)
          fst_name.append(f_name)

      return dxy, dxy_name, fst, fst_name

  # isolation-by-distance function
  ##### slope and r2 of gen ~ geo regression ##### (similar to mantel corr)
  def calc_ibd(gendist, coords):
      
      # scale dxy according to Roussett 1997 (they used FST, but logic still follows)
      gendist = np.asarray(gendist)

      gendist_1 = 1 - gendist

      gendist_scaled = np.divide(gendist, gendist_1, out=np.zeros_like(gendist), where=gendist_1!=0)
      
      # get pairwise geographic distance for all pops
      
      # convert to radians
      long_rad = [radians(x[0]) for x in coords]
      lat_rad = [radians(y[1]) for y in coords]

      geometry = list(zip(long_rad, lat_rad))

      geometry = [list(_) for _ in geometry]

      dist = haversine_distances(geometry) * 6371000/1000  # multiply by Earth radius to get kilometers

      # get the upper diagonal of the distance matrix
      dist = dist[np.triu_indices(dist.shape[0], k=1)]

      
      # take the log10 of geographic distance to scale linearly for IBD regression
      logdist = np.log10(dist)

      dist_df = pd.DataFrame(
          data = {
              "geo_dist": logdist,
              "gen_dist": gendist_scaled
          }
      )

      dist_df = dist_df.dropna()

      # linear model, extracting the R2 and coefficient (slope)
      reg = linear_model.LinearRegression()

      # reshape X so it is 2D
      geo_dist = np.array(dist_df["geo_dist"])
      geo_dist = geo_dist.reshape(-1, 1)
      
      reg.fit(geo_dist, dist_df["gen_dist"])

      r2 = reg.score(geo_dist, dist_df["gen_dist"])
      b = reg.coef_

      return b, r2


  
  # only calculate species-wide stats if there aren't admixture populations
  if counts_array_admix is None:
      sfs = allel.sfs_folded(counts_array)

      # calculate the first 5 Hill numbers of the site frequency spectrum, scaling by the sample size
      sfs_h1 = hill_number(sfs, 1) / len(sfs)
      sfs_h2 = hill_number(sfs, 2) / len(sfs)
      sfs_h3 = hill_number(sfs, 3) / len(sfs)
          
      # average pi across sites
      pi_raw = allel.mean_pairwise_difference(counts_array, fill = np.nan)
      pi = np.nanmean(pi_raw)
      # standard deviation of pi across sites
      pi_sd = np.nanstd(pi_raw)


      # tajima's D 
      taj_d_raw = allel.moving_tajima_d(counts_array, size=100, step=10)
      taj_d = np.nanmean(taj_d_raw)
      taj_d_sd = np.nanstd(taj_d_raw)

      stat_df = pd.DataFrame(
          data = {
              "sfs_h1": sfs_h1,
              "sfs_h2": sfs_h2,
              "sfs_h3": sfs_h3,
              "pi": pi,
              "pi_sd": pi_sd,
              "taj_d": taj_d,
              "taj_d_sd": taj_d_sd,
              "num_var": counts_array.n_variants
          }, index = [0]
      )

      # calculate dxy
      dids = list(demes_coordinates.keys())

      dxy, dxy_name, fst, fst_name = calc_between_deme_diversity(dids)
      
      for name in range(len(dxy_name)):
          stat_df[dxy_name[name]] = dxy[name] 
          stat_df[fst_name[name]] = fst[name]


  # otherwise, calculate stats per admixture population
  # also calculate Hudson's FST and Dxy between the two populations
  else:
      stat_df = pd.DataFrame(
          data = {},
          index = [0]
      )

      stat_df["num_var"] = counts_array.n_variants

      # calc sfs Hill numbers, pi, and tajima's D
      for key in counts_array_admix:
          sfs = allel.sfs_folded(counts_array_admix[key])
          stat_df[f"sfs_h1_a{key}"] = hill_number(sfs, 1) / len(sfs)
          stat_df[f"sfs_h2_a{key}"] = hill_number(sfs, 2) / len(sfs)
          stat_df[f"sfs_h3_a{key}"] = hill_number(sfs, 3) / len(sfs)
          pi_raw = allel.mean_pairwise_difference(counts_array_admix[key])
          stat_df[f"pi_a{key}"] = np.nanmean(pi_raw)
          stat_df[f"pi_sd_a{key}"] = np.nanstd(pi_raw)
          taj_d_raw = allel.moving_tajima_d(counts_array_admix[key], size=100, step=10)
          stat_df[f"taj_d_a{key}"] = np.nanmean(taj_d_raw)
          stat_df[f"taj_d_sd_a{key}"] = np.nanstd(taj_d_raw)
      
      # Dxy and Hudson's FST for admixture populations and Dxy for all pops.
      if between_admix_pop_sumstats:
          for ac_ind in list(itertools.combinations(list(counts_array_admix.keys()), 2)):
              ac1 = counts_array_admix[ac_ind[0]]
              ac2 = counts_array_admix[ac_ind[1]]
              d_raw = allel.mean_pairwise_difference_between(ac1, ac2)
              d = np.nanmean(d_raw)
              d_sd = np.nanstd(d_raw)
              stat_df[f"dxy_a{ac_ind[0]}_{ac_ind[1]}"] = d
              stat_df[f"dxy_sd_a{ac_ind[0]}_{ac_ind[1]}"] = d_sd
              fst_admix, fst_se_admix, _, _ = allel.average_hudson_fst(ac1, ac2, 100)
              stat_df[f"fst_a{ac_ind[0]}_{ac_ind[1]}"] = fst_admix
              stat_df[f"fst_se_a{ac_ind[0]}_{ac_ind[1]}"] = fst_se_admix  
          
          # calculate dxy
          dids = list(demes_coordinates.keys())

          dxy, dxy_name, fst, fst_name = calc_between_deme_diversity(dids)
          
          for name in range(len(dxy_name)):
              stat_df[dxy_name[name]] = dxy[name]       
              stat_df[fst_name[name]] = fst[name]
  

  if counts_array_demes is not None:
      # get pi for all pops
      pi_pops = []
      for key in counts_array_demes:
          pi_pops.append(np.nanmean(allel.mean_pairwise_difference(counts_array_demes[key])))
      
      pi_pops_dict = dict(zip(counts_array_demes.keys(), pi_pops))

      # add pi to dataframe
      for key in pi_pops_dict:
          colname = f"pi_pop_{key}"
          stat_df[colname] = pi_pops_dict[key]

      
      if admix_dict is None:

          # convert the values of the demes_coordinates dictionary into a list
          coords = list(demes_coordinates.values())
          b_dxy, r2_dxy = calc_ibd(dxy, coords)
          b_fst, r2_fst = calc_ibd(fst, coords)
          stat_df["ibd_dxy_slope"] = b_dxy
          stat_df["ibd_dxy_r2"] = r2_dxy
          stat_df["ibd_fst_slope"] = b_fst
          stat_df["ibd_fst_r2"] = r2_fst
          
      else:
          
          for key in admix_dict:
              demes = admix_dict[key]

              # get the coordinates associated with the demes
              coords_d = []
              for d in demes:
                  c = demes_coordinates[d]
                  coords_d.append(c)
              
              ## calculate dxy and fst. This is super fast, so it's easier to do this than try weird subsetting to subset the full IBD matrix for the DXY values we want per admix pop
              dxy, dxy_name, fst, fst_name = calc_between_deme_diversity(demes)

              for name in range(len(dxy_name)):
                  stat_df[dxy_name[name]] = dxy[name] 
                  stat_df[fst_name[name]] = fst[name]

              ## calculate ibd
              b_dxy, r2_dxy = calc_ibd(dxy, coords_d)
              stat_df[f"ibd_dxy_slope_a{key}"] = b_dxy
              stat_df[f"ibd_dxy_r2_a{key}"] = r2_dxy

              b_fst, r2_fst = calc_ibd(fst, coords_d)
              stat_df[f"ibd_fst_slope_a{key}"] = b_fst
              stat_df[f"ibd_fst_r2_a{key}"] = r2_fst
      

  return np.round(stat_df, 6)





```


## E. iheringii

### Read in data

```{python}
#| label: read-data-ihe
filepath = "output/sdm_projections/projections_ihe.tif"

r = rasterio.open(filepath)

r2 = r.read(masked=True)

localities = pd.read_csv("data/enyalius_locs_genetics.csv")

localities = localities[localities["species"] == "iheringii"]

# assign an identifier for the "STRUCTURE" population assignment
k2_loc_ids = ["cana", "jara", "prai", "grao"]

spop = np.ones(len(localities["loc_code"]), dtype = np.int8)
for i in range(len(localities["loc_code"])):
    for j in range(len(k2_loc_ids)):
        if localities["loc_code"][localities["loc_code"].index[i]] == k2_loc_ids[j]:
            spop[i] = 2

# "STRUCTURE" population
localities["admix_ids"] = spop

coords = list(zip(localities.longitude, localities.latitude))
```

### Create admix ID raster

```{python}
#| label: admix-id-rast-ihe

admix_id_out = "output/admix_rasters/admix_id_rast_ihe.tif"
# create admixture population raster mask
split_landscape_by_admix_pop(filepath, coords, admix_id = localities["admix_ids"], outfile = admix_id_out, band_index=1, mask_rast=False)
```

### Create empirical dictionaries

```{python}
#| label: sample-dict-ihe

gen_path = "data/vcfs/clust92_iheringii_0.6_nosingletons.vcf"

pop_dict_sim, pop_dict_sim_long, pop_dict_empirical = coords_to_sample_dict_empirical(r, coords, individual_ids=localities["id_code"], vcf_path=gen_path)
```


```{python}
#| label: admix-dict-ihe
admix_dict = admix_to_deme_dict(admix_id_out, pop_dict_empirical)
```

```{python}
#| label: coord-dict-ihe
coord_dict = sampled_cells_to_coords(r, coords)
```


### Allele counts matrices

```{python}
#| label: ac-mat-ihe

# allele counts matrices for empirical populations
gc_emp, gc_emp_demes, gc_emp_admix = counts_from_vcf(vcf=gen_path, pops_dict=pop_dict_empirical, pops_dict_admix=admix_dict, r2_thresh = 0.1)

```

### Calculate summary statistics


```{python}
#| label: calc-sumstats-ihe

# I get efficiency warnings for how I add to the pandas data frame. This takes only a couple seconds anyways, so I'm not worried about it
with warnings.catch_warnings():
  warnings.simplefilter("ignore")
  sumstats_empirical = calc_sumstats(counts_array = gc_emp, demes_coordinates = coord_dict, admix_dict=admix_dict, counts_array_demes=gc_emp_demes, counts_array_admix=gc_emp_admix)
```


```{python}
#| label: view-sumstats-ihe

sumstats_empirical
```

### Write sumstats to file


```{python}
#| label: sumstats-to-file-ihe
#| eval: false

sumstats_empirical.to_csv("output/empirical_sumstats/iheringii_sumstats.csv")
```

## E. catenatus

### Read in data

```{python}
#| label: read-data-cat
filepath = "output/sdm_projections/projections_cat_inland-removed.tif"

r = rasterio.open(filepath)

r2 = r.read(masked=True)

localities = pd.read_csv("data/enyalius_locs_genetics.csv")

localities = localities[localities["species"] == "catenatus"]

# assign an identifier for the "STRUCTURE" population assignment
cat_pop_1_inds = pd.read_table("data/snmf_ind_lists/catenatus_pop_1_ind.txt")
cat_pop_2_inds = pd.read_table("data/snmf_ind_lists/catenatus_pop_2_ind.txt")
cat_pop_3_inds = pd.read_table("data/snmf_ind_lists/catenatus_pop_3_ind.txt")

spop = np.zeros(len(localities["id_code"]), dtype = np.int8)
for i in range(len(localities["id_code"])):
    for j in range(len(cat_pop_1_inds.id)):
        if localities["id_code"][localities["id_code"].index[i]] == cat_pop_1_inds.id[j]:
            spop[i] = 1
    for j in range(len(cat_pop_2_inds.id)):
        if localities["id_code"][localities["id_code"].index[i]] == cat_pop_2_inds.id[j]:
            spop[i] = 2
    for j in range(len(cat_pop_3_inds.id)):
        if localities["id_code"][localities["id_code"].index[i]] == cat_pop_3_inds.id[j]:
            spop[i] = 3

# "STRUCTURE" population
localities["admix_ids"] = spop

# remove inland individuals
inland_inds = ["cat_jeq_MTR17108", "cat_jeq_MTR17172", "cat_jeq_MTR17377", "cat_mig_MTR19889", "cat_mig_RPD188", "cat_rem_MTR19915", "cat_rem_RPD128"]

localities = localities[~localities['id_code'].isin(inland_inds)]

# isolate the coordinates as a list of tuples
coords = list(zip(localities.longitude, localities.latitude))
```


### Create admix ID raster

```{python}
#| label: admix-id-rast-cat

admix_id_out = "output/admix_rasters/admix_id_rast_cat.tif"
# create admixture population raster mask
split_landscape_by_admix_pop(filepath, coords, admix_id = localities["admix_ids"], outfile = admix_id_out, band_index=1, mask_rast=False)
```

```{python}
#| label: admix-id-map

admix_r_cat = rasterio.open(admix_id_out)

plt.imshow(admix_r_cat.read(1), cmap = "viridis")

plt.show()
```


### Create empirical dictionaries

```{python}
#| label: sample-dict-cat
gen_path = "data/vcfs/clust92_catenatus_0.6_nosingletons.vcf"

pop_dict_sim, pop_dict_sim_long, pop_dict_empirical = coords_to_sample_dict_empirical(r, coords, individual_ids=localities["id_code"], vcf_path=gen_path)
```


```{python}
#| label: admix-dict-cat
admix_dict = admix_to_deme_dict(admix_id_out, pop_dict_empirical)
```

```{python}
#| label: coord-dict-cat
coord_dict = sampled_cells_to_coords(r, coords)
```


### Allele counts matrices

```{python}
#| label: ac-mat-cat

# allele counts matrices for empirical populations
gc_emp, gc_emp_demes, gc_emp_admix = counts_from_vcf(vcf=gen_path, pops_dict=pop_dict_empirical, pops_dict_admix=admix_dict, r2_thresh = 0.1)

```

### Calculate summary statistics

```{python}
#| label: calc-sumstats-cat

# I get efficiency warnings for how I add to the pandas data frame. This takes only a couple seconds anyways, so I'm not worried about it
with warnings.catch_warnings():
  warnings.simplefilter("ignore")
  sumstats_empirical = calc_sumstats(counts_array = gc_emp, demes_coordinates = coord_dict, admix_dict=admix_dict, counts_array_demes=gc_emp_demes, counts_array_admix=gc_emp_admix)
```


```{python}
#| label: view-sumstats-cat
sumstats_empirical
```

### Write sumstats to file


```{python}
#| label: sumstats-to-file-cat
#| eval: false

sumstats_empirical.to_csv("output/empirical_sumstats/catenatus_sumstats.csv")
```

## E. perditus

### Read in data

E. perditus from pop 1 are actually a different species. I ran an earlier version of sNMF including them. I need to rerun sNMF without the pop 1 individuals.

```{python}
#| label: read-data-per
filepath = "output/sdm_projections/projections_per.tif"

r = rasterio.open(filepath)

r2 = r.read(masked=True)

localities = pd.read_csv("data/enyalius_locs_genetics.csv")

localities = localities[localities["species"] == "perditus"]

# snmf assignment
per_snmf = pd.read_csv("output/snmf/perditus/pop_assignment_a10_k3.csv")

# assign an identifier for the "STRUCTURE" population assignment
per_pop_1_inds = per_snmf[per_snmf["likely_assignment"] == "pop_1"][["id"]]["id"].unique()
per_pop_2_inds = per_snmf[per_snmf["likely_assignment"] == "pop_2"][["id"]]["id"].unique()
per_pop_3_inds = per_snmf[per_snmf["likely_assignment"] == "pop_3"][["id"]]["id"].unique()
#per_pop_4_inds = per_snmf[per_snmf["likely_assignment"] == "pop_4"][["id"]]["id"].unique()

spop = np.zeros(len(localities["id_code"]), dtype = np.int8)
for i in range(len(localities["id_code"])):
    for j in range(len(per_pop_1_inds)):
        if localities["id_code"][localities["id_code"].index[i]] == per_pop_1_inds[j]:
            spop[i] = 1
    for j in range(len(per_pop_2_inds)):
        if localities["id_code"][localities["id_code"].index[i]] == per_pop_2_inds[j]:
            spop[i] = 2
    for j in range(len(per_pop_3_inds)):
        if localities["id_code"][localities["id_code"].index[i]] == per_pop_3_inds[j]:
            spop[i] = 3
    # for j in range(len(per_pop_4_inds)):
    #     if localities["id_code"][localities["id_code"].index[i]] == per_pop_4_inds[j]:
    #         spop[i] = 4

# "STRUCTURE" population
localities["admix_ids"] = spop

# isolate the coordinates as a list of tuples
coords = list(zip(localities.longitude, localities.latitude))
```


### Create admix ID raster

```{python}
#| label: admix-id-rast-per

admix_id_out = "output/admix_rasters/admix_id_rast_per.tif"
# create admixture population raster mask
split_landscape_by_admix_pop(filepath, coords, admix_id = localities["admix_ids"], outfile = admix_id_out, band_index=1, mask_rast=False)
```

```{python}
#| label: admix-id-map

admix_r_per = rasterio.open(admix_id_out)

plt.imshow(admix_r_per.read(1), cmap = "viridis")

plt.show()
```


### Create empirical dictionaries

```{python}
#| label: sample-dict-per
gen_path = "data/vcfs/clust92_perditus_0.6_nosingletons.vcf"

pop_dict_sim, pop_dict_sim_long, pop_dict_empirical = coords_to_sample_dict_empirical(r, coords, individual_ids=localities["id_code"], vcf_path=gen_path)
```


```{python}
#| label: admix-dict-per
admix_dict = admix_to_deme_dict(admix_id_out, pop_dict_empirical)
```

```{python}
#| label: coord-dict-per
coord_dict = sampled_cells_to_coords(r, coords)
```


### Allele counts matrices

```{python}
#| label: ac-mat-per

# allele counts matrices for empirical populations
gc_emp, gc_emp_demes, gc_emp_admix = counts_from_vcf(vcf=gen_path, pops_dict=pop_dict_empirical, pops_dict_admix=admix_dict, r2_thresh = 0.1)

```

### Calculate summary statistics

```{python}
#| label: calc-sumstats-per

# I get efficiency warnings for how I add to the pandas data frame. This takes only a couple seconds anyways, so I'm not worried about it
with warnings.catch_warnings():
  warnings.simplefilter("ignore")
  sumstats_empirical = calc_sumstats(counts_array = gc_emp, demes_coordinates = coord_dict, admix_dict=admix_dict, counts_array_demes=gc_emp_demes, counts_array_admix=gc_emp_admix)
```


```{python}
#| label: view-sumstats-per
sumstats_empirical
```

### Write sumstats to file


```{python}
#| label: sumstats-to-file-per
#| eval: false

sumstats_empirical.to_csv("output/empirical_sumstats/perditus_sumstats.csv")
```

