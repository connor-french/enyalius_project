---
title: "Species Distribution Modeling"
output:
  html_document:
    toc: true
    toc_float: 
      toc_depth: 4
      collapsed: false
---

I am modeling the distributions of the four *Enyalius* study species (*E. catenatus*, *E. pictus*, *E. perditus*, and *E. iheringii*) to understand their current distributions and responses to long-term historical climate change.  

I will build robust models of their current distributions using recent environmental data (i.e. last few decades). Then, I will build similar models with variables that are available for both present-day and historical (i.e. last glacial maximum) time periods. I will use the **current** models as benchmarks for the performance of the models intended for hindcasting.  

```{r setup, message=FALSE, warning=FALSE}
library(sf)
library(spThin)
library(janitor)
library(here)
library(rasterVis)
library(tidyverse)
library(ENMeval)
library(patchwork)
library(terra)
```


# Current

## Variable selection

I'm choosing variables that encompass the range of the *Enyalius* species, are relevant to their physiology, and are obtainable at a reasonable spatial resolution. 

Bioclims:  
Using the BrazilClim dataset downloaded from Ramoni-Perazzi, P., Passamani, M., Thielen, D., Padovani, C., Arizapana-Almonacid, M.A., 2021. BrazilClim : The overcoming of limitations of pre‚Äêexisting bioclimate data. Int. J. Climatol. https://doi.org/10.1002/joc.7325. Downloaded on __2022-02-25__.  
1 km resolution.  

Land Cover:  
Using the forest land cover rasters (classes 1-4) from Tuanmu, M.-N. and W. Jetz. 2014. A global 1-km consensus land-cover product for biodiversity and ecosystem modeling. Global Ecology and Biogeography 23(9): 1031-1045. Downloaded on __2022-02-26__.  
1 km resolution  

## Variable processing

I'm cropping the variables to a relevant extent before going further with the individual SDMs. I'm cropping them with a 1 degree buffer around the entire species group's range. 

First, I'm reading in the localities and plotting them to make sure there isn't anything wild. Everything looks reasonable!  

```{r, locs, message=FALSE, eval=FALSE}
# read in as a data frame first
locs_df <- read_csv(here("analysis", "data", "enyalius_locs.csv")) %>% 
  # the variable names are messy
  janitor::clean_names() %>%
  filter(!is.na(latitude), !is.na(longitude),
         # remove localities that are only mapped to a Google Earth municipality. The reserve in the "GPS of the reserve" locality is barely a km, so that is acceptable error relative to the environmental resolution
         source_lat_long != "Google Earth municipality") %>%
  # there are some lat/longs with spaces. Need to fix this
  mutate(longitude = str_remove(longitude, "\\s"), 
         latitude = str_remove(latitude, "\\s")) %>% 
  # convert to numeric
  mutate(longitude = as.numeric(longitude),
         latitude = as.numeric(latitude))

# convert to sf for spatial operations
locs_sf <- st_as_sf(locs_df, 
                    coords = c("longitude", "latitude"),
                    crs = 4326)

# convert to vect for interacting with terra
locs_vec <- vect(locs_sf)

# atlantic forest shapefile for plotting
af <- read_sf(here("analysis", "data", "atlantic_forest", "atlantic_forest.geojson"))

# plot
ggplot() +
  geom_sf(data = st_geometry(af)) +
  geom_sf(data = locs_sf)
```

Creating a convex hull with a 1 degree buffer.  

```{r mcp-all, warning=FALSE, eval=FALSE}
mcp_all <- st_convex_hull(st_union(locs_sf)) %>%
  st_buffer(dist = 1.0) %>% 
  terra::vect()

plot(st_geometry(af))
plot(mcp_all, add=TRUE)
plot(locs_vec, add=TRUE)
```

Crop bioclims.  

```{r crop-env, eval=FALSE}
bioclims <- terra::rast(list.files(here("analysis", "data", "brazil_clim"), full.names = TRUE)) %>% 
  terra::crop(mcp_all) %>% 
  terra::mask(mcp_all)

# fix the names  
names(bioclims) <- str_remove(names(bioclims), "BC1.0_")


plot(bioclims$bio_01)
plot(st_geometry(af), add=TRUE)
plot(mcp_all, add=TRUE)
plot(locs_vec, add=TRUE)
```

Crop forest cover. The class 01 variable, needleleaf forest, isn't present in the AF, so that's why you don't see it here.

```{r, eval=FALSE}
forest_cover <- terra::rast(list.files(here("analysis", "data", "forest_cover"), full.names = TRUE)) %>% 
  terra::crop(mcp_all) %>% 
  terra::mask(mcp_all) 
# fix the names  
names(forest_cover) <- paste0("fc_", names(forest_cover)) %>% str_replace("\\-", "\\_")

plot(forest_cover$fc_04_mixed)
plot(st_geometry(af), add=TRUE)
plot(mcp_all, add=TRUE)
plot(locs_vec, add=TRUE)
```

Write the cropped climate and forest cover layers to file for use in the SDMs.  

```{r, eval=FALSE}
terra::writeRaster(bioclims, here("analysis", "output", "cropped_predictors", "bioclims.tif"))
terra::writeRaster(forest_cover, here("analysis", "output", "cropped_predictors", "forest_cover.tif"))
```

## General SDM steps {.tabset}
For each SDM, I'm going to perform the following steps:  

 * spatially thin localities  
 * crop the new predictors according to a minimum convex hull of the localities for each species with a 0.5 degree buffer 
 * extract background environmental data (10,000 points) for predictor correlation and modeling
 * correlate predictors
 * remove predictors w/ r > 0.75, prioritizing ecologically relevant variables  
 * Use Maxent for modeling
     * LQH feature classes to keep models relatively simple  
     * regularization multipliers from 0.5 to 5.0 in 0.5 increments to test a wide range of regularization
     * leave-one-out cross validation for model selection due to a low number of localities
     * select models first by AICc (model fit), followed by ommission error rate (prediction)  

In addition, I'm reading/writing data for each species in isolation, so the code for one species isn't dependent on that for another, or for what I did during variable processing.  

### E. catenatus

Note: putative "catenatus 2" species from Mariana's phylogenetic work have been removed.  

Reading in data for plotting.  

```{r}
# atlantic forest shapefile
af <- read_sf(here("analysis", "data", "atlantic_forest", "atlantic_forest.geojson"))
```


#### Spatial thin

Read and filter localities.  

```{r}
locs_cat <- read_csv(here("analysis", "data", "enyalius_locs.csv")) %>% 
  # the variable names are messy
  janitor::clean_names() %>%
  filter(species == "catenatus",
    !is.na(latitude), !is.na(longitude),
    # remove duplicates
    !duplicated(latitude),
         # remove localities that are only mapped to a Google Earth municipality. The reserve in the "GPS of the reserve" locality is barely a km, so that is acceptable error relative to the environmental resolution
         source_lat_long != "Google Earth municipality") %>%
  # there are some lat/longs with spaces. Need to fix this
  mutate(longitude = str_remove(longitude, "\\s"), 
         latitude = str_remove(latitude, "\\s")) %>% 
  # convert to numeric
  mutate(longitude = as.numeric(longitude),
         latitude = as.numeric(latitude)) %>% 
  # convert to sf for spatial operations
  st_as_sf(coords = c("longitude", "latitude"),
           crs = 4326,
           remove = FALSE)

# plot localities
plot(st_geometry(af))
plot(st_geometry(locs_cat), add = TRUE)
```

Spatial thin. I'm using a 5 km buffer   

```{r}
set.seed(29833)

#run spthin algorithm. This returns 100 possible combinations of removed localities
output <-
  spThin::thin(
    locs_cat,
    'latitude',
    'longitude',
    'species',
    thin.par = 5,
    reps = 100,
    locs.thinned.list.return = TRUE,
    write.files = FALSE,
    verbose = FALSE
  )

# I want to maximize the # of localities returned  
maxThin <- which(sapply(output, nrow) == max(sapply(output, nrow)))

# if there are multiple iterations with the max # of localities, pick one
maxThin <-
  output[[ifelse(length(maxThin) > 1, maxThin[1], maxThin)]]

# subset locs to match only thinned locs
locs_cat <- locs_cat[as.numeric(rownames(maxThin)), ]

# get the unused locs as a testing data set
# this probably isn't useful since they will overlap heavily with the training data, but seems like another piece of info to look at
test_cat <- locs_cat[-as.numeric(rownames(maxThin)), ]

plot(st_geometry(af))
plot(st_geometry(locs_cat), add=TRUE)
```

Write thinned localities to file  

```{r, eval=FALSE}
# Write to file
st_write(locs_cat, here("analysis", "output", "thinned_localities", "catenatus_thinned.geojson"),
         delete_dsn = TRUE)
```

#### Crop environment

First, I need to read in the environmental data.  

```{r}
bioclims <- terra::rast(here("analysis", "output", "cropped_predictors", "bioclims.tif"))
forest_cover <- terra::rast(here("analysis", "output", "cropped_predictors", "forest_cover.tif"))
```


Cropping and combining variables for analysis.  

```{r}
mcp_cat <- st_convex_hull(st_union(locs_cat)) %>%
  st_buffer(dist = 0.5) %>% 
  terra::vect()

bioclims_cat <- bioclims %>%
  # the bioclims are in a slightly different CRS
  terra::project(forest_cover) %>% 
  terra::crop(mcp_cat) %>% 
  terra::mask(mcp_cat)

forest_cover_cat <- forest_cover %>% 
  terra::crop(bioclims_cat) %>% 
  terra::mask(bioclims_cat[[1:3]]) 

plot(bioclims_cat[[1]])
plot(forest_cover_cat[[1]])

predictors_cat <- c(bioclims_cat, forest_cover_cat)
```


#### Predictor correlation

Sample 10000 background points.  

```{r, warning=FALSE}
set.seed(19874)

# for variable correlations
bg_envt_cat <- terra::spatSample(predictors_cat, 10000, 
                               warn=TRUE, 
                               na.rm = TRUE, 
                               as.df = TRUE,
                               xy = TRUE)

# for use in ENMevaluate
bg_coords_cat <- bg_envt_cat[,c("x", "y")]
```

Next, I'll extract the values for the localities and calculate the correlations among variables.  

```{r, warning=FALSE, message=FALSE}
# extract values
bg_corr_cat <- bg_envt_cat %>% select(-x, -y)

# correlation dataframe
corr_df_cat <- corrr::correlate(bg_corr_cat, method = "pearson") 

# only retain correlations >= 0.75 for visualizing and deciding which to remove
corr_df_75_cat <- corr_df_cat %>% 
  # replace NAs first
  mutate(across(everything(), 
                ~replace_na(., 0)),
         # take absolute value of all values to make filtering easier. I'm not interested in the direction 
         across(where(is.numeric), abs)) %>% 
  # only keep values 
  mutate(across(everything(),
                ~ ifelse(. < 0.75, 0, .)))

corrr::rplot(corr_df_75_cat)
```

I'm prioritizing measures of climate extremes and environmental variability over averages to incorporate information about ecological limits rather than averages. In terms of bioclims, this comes out to BIO4 (temperature seasonality), BIO5 (max temp of the warmest month), BIO6 (min temp of the coldest month), BIO7 (annual temp range), BIO13 (prec of the wettest month), BIO14 (prec of the driest month), BIO15 (prec seasonality).  
None of the forest cover variables are correlated with anything else.  

Variable: what the variable is correlated with.  
**BIO4**: Nothing  
**BIO5**: BIO1, BIO9, BIO10, BIO11  
**BIO6**: BIO1, BIO9, BIO10, BIO11  
**BIO7**: BIO2
**BIO13**: BIO12, BIO16
**BIO14**: BIO12, BIO17, BIO19
**BIO15**: Nothing


The final variable list:
BIO4, BIO5, BIO6, BIO7, BIO13, BIO14, BIO15, forest cover (3 vars)  

```{r}
predictors_cat <- predictors_cat[[c("bio_04", "bio_05", "bio_06", "bio_07", "bio_13", "bio_14", "bio_15", "fc_02_evergreen_broadleaf", "fc_03_deciduous_broadleaf", "fc_04_mixed")]]
```


#### Maxent model

I'm using a jackknifing model evaluation approach since I only have 26 observations and a previous attempt for spatial CV led to wonky evaluation metrics.  

```{r}
set.seed(817)
coords_cat <- st_coordinates(locs_cat)
colnames(coords_cat) <- c("x", "y")

folds_cat <- ENMeval::get.jackknife(occ = coords_cat, 
                            bg = bg_coords_cat)
```


Run the model. Predictions are clamped to prevent extrapolation. This part takes a little bit. 29 minutes 57 sec on the wall clock on a 2020 M1 MacBook air with 6 cores and 16 GB of memory. Probably because of the high number of background points and the wide range of regularization multipliers I'm exploring.    

```{r, eval=FALSE}
set.seed(832)

# the vector of regularization multipliers to test
rms <- seq(0.5, 5, 0.5)

# convert the terra object to a raster stack for use in EMNeval
predictors_cat_stack <- raster::stack(predictors_cat)

# iterate model building over all chosen parameter settings
sdm_cat <-
  ENMeval::ENMevaluate(
    occs = coords_cat,
    envs = predictors_cat_stack,
    bg.coords = bg_coords_cat,
    RMvalues = rms,
    fc = c('L', 'LQ', 'H', 'LQH'),
    # clamping to prevent model extrapolation
    doClamp = TRUE,
    taxon.name = "catenatus",
    partitions = "user",
    # going to do a separate run with the final model on testing data
    #occs.testing = test_cat,
    user.grp = folds_cat,
    bg.grp,
    clamp = TRUE,
    algorithm = "maxnet",
    parallel = TRUE,
    numCores = 6
  )
```

```{r, eval=FALSE}
# write the model to file
write_rds(sdm_cat, here("analysis", "output", "sdm_models", "sdm_catenatus.rds"))
```

```{r, echo=FALSE}
sdm_cat <- read_rds(here("analysis", "output", "sdm_models", "sdm_catenatus.rds"))
```

##### Model evaluation

Let's take a look at the model results.  
```{r}
eval_table_cat <- sdm_cat@results
eval_mods_cat <- sdm_cat@models

names(eval_mods_cat) <-
  str_replace_all(names(eval_mods_cat), "\\.", "\\_")
```

Select the final model. First I'm looking at plots of model evaluation stats to get an idea of the spread of stats.  

```{r, warning=FALSE}
daic_cat <- ggplot(data = eval_table_cat, aes(x = rm, y = delta.AICc, color = fc)) +
  geom_point() +
  scale_color_viridis_d() +
  theme_bw()

or_cat <- ggplot(data = eval_table_cat, aes(x = rm, y = or.10p.avg, color = fc)) +
  geom_point() +
  scale_color_viridis_d() +
  theme_bw()

dauc_cat <- ggplot(data = eval_table_cat, aes(x = rm, y = auc.diff.avg, color = fc)) +
  geom_point() +
  scale_color_viridis_d() +
  theme_bw()

cbi_cat <- ggplot(data = eval_table_cat, aes(x = rm, y = cbi.val.avg, color = fc)) +
  geom_point() +
  scale_color_viridis_d() +
  theme_bw()

(daic_cat + or_cat) / (dauc_cat + cbi_cat)
```

Now I'm going to take a look at tables of delta AICc, omission rate, and AUC to see how close the models are. The model with the lowest AICc has a regularization multiplier of 4.5 and LQH feature classes. It also has a reasonable omission rate and AUC. I will go forward with this model.   

```{r}
eval_table_cat %>% 
  select(delta.AICc, AICc, or.10p.avg, auc.diff.avg, auc.val.avg, rm, fc) %>%
  arrange(delta.AICc) %>% 
  head(10) %>% 
  knitr::kable()
```

Select model.  

```{r}
mod_cat <- eval_mods_cat$rm_4_5_fc_LQH
opt_seq_tune_cat <- eval_table_cat$tune.args[na.omit(eval_table_cat$delta.AICc) == 0]
```

Plot the response curves.  
Only fc_02 and fc_04 have any effect on occurrence. Interesting! Suitability increases with evergreen broadleaf and decreases with mixed forest.  
```{r}
#plot(mod_cat, vars = c("fc_02_evergreen_broadleaf", "fc_04_mixed"), type = "cloglog")
```


##### Project

I'm projecting the model to the study area extent.  
```{r}
pred_cat <- ENMeval::eval.predictions(sdm_cat)[[opt_seq_tune_cat]]
plot(pred_cat)
plot(st_geometry(af), add = TRUE)
plot(st_geometry(locs_cat), pch = 21, bg = alpha("lightgray", 0.5), add = TRUE)
```



### E. pictus

Reading in data for plotting.  

```{r}
# atlantic forest shapefile
af <- read_sf(here("analysis", "data", "atlantic_forest", "atlantic_forest.geojson"))
```


#### Spatial thin

Read and filter localities.  

```{r}
locs_pic <- read_csv(here("analysis", "data", "enyalius_locs.csv")) %>% 
  # the variable names are messy
  janitor::clean_names() %>%
  filter(species == "pictus",
    !is.na(latitude), !is.na(longitude),
    # remove duplicates
    !duplicated(latitude),
         # remove localities that are only mapped to a Google Earth municipality. The reserve in the "GPS of the reserve" locality is barely a km, so that is acceptable error relative to the environmental resolution
         source_lat_long != "Google Earth municipality") %>%
  # there are some lat/longs with spaces. Need to fix this
  mutate(longitude = str_remove(longitude, "\\s"), 
         latitude = str_remove(latitude, "\\s")) %>% 
  # convert to numeric
  mutate(longitude = as.numeric(longitude),
         latitude = as.numeric(latitude)) %>% 
  # convert to sf for spatial operations
  st_as_sf(coords = c("longitude", "latitude"),
           crs = 4326,
           remove = FALSE)

# plot localities
plot(st_geometry(af))
plot(st_geometry(locs_pic), add = TRUE)
```

Spatial thin. I'm using a 5 km buffer   

```{r}
set.seed(1873)

#run spthin algorithm. This returns 100 possible combinations of removed localities
output <-
  spThin::thin(
    locs_pic,
    'latitude',
    'longitude',
    'species',
    thin.par = 5,
    reps = 100,
    locs.thinned.list.return = TRUE,
    write.files = FALSE,
    verbose = FALSE
  )

# I want to maximize the # of localities returned  
maxThin <- which(sapply(output, nrow) == max(sapply(output, nrow)))

# if there are multiple iterations with the max # of localities, pick one
maxThin <-
  output[[ifelse(length(maxThin) > 1, maxThin[1], maxThin)]]

# subset locs to match only thinned locs
locs_pic <- locs_pic[as.numeric(rownames(maxThin)), ]

# get the unused locs as a testing data set
# this probably isn't useful since they will overlap heavily with the training data, but seems like another piece of info to look at
test_pic <- locs_pic[-as.numeric(rownames(maxThin)), ]

plot(st_geometry(af))
plot(st_geometry(locs_pic), add=TRUE)
```

Write thinned localities to file  

```{r, eval=FALSE}
# Write to file
st_write(locs_pic, here("analysis", "output", "thinned_localities", "pictus_thinned.geojson"),
         delete_dsn = TRUE)
```

#### Crop environment

First, I need to read in the environmental data.  

```{r}
bioclims <- terra::rast(here("analysis", "output", "cropped_predictors", "bioclims.tif"))
forest_cover <- terra::rast(here("analysis", "output", "cropped_predictors", "forest_cover.tif"))
```


Cropping and combining variables for analysis.  

```{r}
mcp_pic <- st_convex_hull(st_union(locs_pic)) %>%
  st_buffer(dist = 0.5) %>% 
  terra::vect()

bioclims_pic <- bioclims %>%
  # the bioclims are in a slightly different CRS
  terra::project(forest_cover) %>% 
  terra::crop(mcp_pic) %>% 
  terra::mask(mcp_pic)

forest_cover_pic <- forest_cover %>% 
  terra::crop(bioclims_pic) %>% 
  terra::mask(bioclims_pic[[1:3]]) 

plot(bioclims_pic[[1]])
plot(st_geometry(locs_pic), add = TRUE)
plot(forest_cover_pic[[1]])
plot(st_geometry(locs_pic), add = TRUE)

predictors_pic <- c(bioclims_pic, forest_cover_pic)
```


#### Predictor correlation

Sample 10000 background points.  

```{r}
set.seed(888874)

# for variable correlations
bg_envt_pic <- terra::spatSample(predictors_pic, 10000, 
                               warn=TRUE, 
                               na.rm = TRUE, 
                               as.df = TRUE,
                               xy = TRUE)

# for use in ENMevaluate
bg_coords_pic <- bg_envt_pic[,c("x", "y")]
```

Next, I'll extract the values for the localities and calculate the correlations among variables.  

```{r}
# extract values
bg_corr_pic <- bg_envt_pic %>% select(-x, -y)

# correlation dataframe
corr_df_pic <- corrr::correlate(bg_corr_pic, method = "pearson") 

# only retain correlations >= 0.75 for visualizing and deciding which to remove
corr_df_75_pic <- corr_df_pic %>% 
  # replace NAs first
  mutate(across(everything(), 
                ~replace_na(., 0)),
         # take absolute value of all values to make filtering easier. I'm not interested in the direction 
         across(where(is.numeric), abs)) %>% 
  # only keep values 
  mutate(across(everything(),
                ~ ifelse(. < 0.75, 0, .)))

corrr::rplot(corr_df_75_pic)
```

I'm prioritizing measures of climate extremes and environmental variability over averages to incorporate information about ecological limits rather than averages. In terms of bioclims, this comes out to BIO4 (temperature seasonality), BIO5 (max temp of the warmest month), BIO6 (min temp of the coldest month), BIO7 (annual temp range), BIO13 (prec of the wettest month), BIO14 (prec of the driest month), BIO15 (prec seasonality).  
None of the forest cover variables are correlated with anything else.  

Variable: what the variable is correlated with.  
**BIO4**: Nothing  
**BIO5**: BIO1, BIO9, BIO10, BIO11  
**BIO6**: BIO1, BIO8, BIO10, BIO11  
**BIO7**: BIO2, **BIO15**  
**BIO13**: BIO16  
**BIO14**: BIO12, BIO12, **BIO15**, BIO17, BIO19
*X* **BIO15**: BIO2, **BIO7**, **BIO14**, BIO17, BIO19

BIO15 (prec seasonality) is a tough variable to model and it's correlated with two other more reliable variables, so I'm omitting it from consideration.  

The final variable list:
BIO4, BIO5, BIO6, BIO7, BIO13, BIO14, forest cover (3 vars)  

```{r}
predictors_pic <- predictors_pic[[c("bio_04", "bio_05", "bio_06", "bio_07", "bio_13", "bio_14",  "fc_02_evergreen_broadleaf", "fc_03_deciduous_broadleaf", "fc_04_mixed")]]
```


#### Maxent model

I'm using a jackknifing model evaluation approach since I only have 15 observations. 

```{r}
set.seed(77717)
coords_pic <- st_coordinates(locs_pic)
colnames(coords_pic) <- c("x", "y")

folds_pic <- ENMeval::get.jackknife(occ = coords_pic, 
                            bg = bg_coords_pic)
```


Run the model. Predictions are clamped to prevent extrapolation. This part takes a little bit. 29 minutes 57 sec on the wall clock on a 2020 M1 MacBook air with 6 cores and 16 GB of memory. Probably because of the high number of background points and the wide range of regularization multipliers I'm exploring.    

```{r, eval=FALSE}
set.seed(839767)

# the vector of regularization multipliers to test
rms <- seq(0.5, 5, 0.5)

# convert the terra object to a raster stack for use in EMNeval
predictors_pic_stack <- raster::stack(predictors_pic)

# iterate model building over all chosen parameter settings
sdm_pic <-
  ENMeval::ENMevaluate(
    occs = coords_pic,
    envs = predictors_pic_stack,
    bg.coords = bg_coords_pic,
    RMvalues = rms,
    fc = c('L', 'LQ', 'H', 'LQH'),
    # clamping to prevent model extrapolation
    doClamp = TRUE,
    taxon.name = "pictus",
    partitions = "user",
    # going to do a separate run with the final model on testing data
    #occs.testing = test_pic,
    user.grp = folds_pic,
    bg.grp,
    clamp = TRUE,
    algorithm = "maxent.jar",
    parallel = TRUE,
    numCores = 6
  )
```

```{r, eval=FALSE}
# write the model to file
write_rds(sdm_pic, here("analysis", "output", "sdm_models", "sdm_picta.rds"))
```

```{r, echo=FALSE}
sdm_pic <- read_rds(here("analysis", "output", "sdm_models", "sdm_picta.rds"))
```

##### Model evaluation

Let's take a look at the model results.  
```{r}
eval_table_pic <- sdm_pic@results
eval_mods_pic <- sdm_pic@models

names(eval_mods_pic) <-
  str_replace_all(names(eval_mods_pic), "\\.", "\\_")
```

Select the final model. First I'm looking at plots of model evaluation stats to get an idea of the spread of stats.  

```{r}
daic_pic <- ggplot(data = eval_table_pic, aes(x = rm, y = delta.AICc, color = fc)) +
  geom_point() +
  scale_color_viridis_d() +
  theme_bw()

or_pic <- ggplot(data = eval_table_pic, aes(x = rm, y = or.10p.avg, color = fc)) +
  geom_point() +
  scale_color_viridis_d() +
  theme_bw()

dauc_pic <- ggplot(data = eval_table_pic, aes(x = rm, y = auc.diff.avg, color = fc)) +
  geom_point() +
  scale_color_viridis_d() +
  theme_bw()

cbi_pic <- ggplot(data = eval_table_pic, aes(x = rm, y = cbi.val.avg, color = fc)) +
  geom_point() +
  scale_color_viridis_d() +
  theme_bw()

(daic_pic + or_pic) / (dauc_pic + cbi_pic)
```

Now I'm going to take a look at tables of delta AICc, omission rate, and AUC to see how close the models are. The model with the lowest AICc has a regularization multiplier of 1 and L feature class. It also has a reasonable omission rate and AUC. I will go forward with this model.   

```{r}
eval_table_pic %>% 
  select(delta.AICc, AICc, or.10p.avg, auc.diff.avg, auc.val.avg, rm, fc) %>%
  arrange(delta.AICc) %>% 
  head(10) %>% 
  knitr::kable()
```

Select model.  

```{r}
mod_pic <- eval_mods_pic$rm_1_fc_L
opt_seq_tune_pic <- eval_table_pic$tune.args[na.omit(eval_table_pic$delta.AICc) == 0][1]
```

Variable importance. It looks like forests are important again! In addition to precipitation.  
```{r}
plot(mod_pic)
```

Plot the response curves. BIO14, fc_02, amd fc_03 are positively related with presence, while fc_04 is weakly negatively related

```{r}
dismo::response(mod_pic)
```


##### Project

I'm projecting the model to the study area extent.  
```{r}
pred_pic <- ENMeval::eval.predictions(sdm_pic)[[opt_seq_tune_pic]]
plot(pred_pic)
plot(st_geometry(af), add = TRUE)
plot(st_geometry(locs_pic), pch = 21, bg = alpha("lightgray", 0.5), add = TRUE)
```


### E. perditus

Note: putative "perditus 2" species localities from Mariana's phylogenetics work have been removed 

Reading in data for plotting.  

```{r}
# atlantic forest shapefile
af <- read_sf(here("analysis", "data", "atlantic_forest", "atlantic_forest.geojson"))
```


#### Spatial thin

Read and filter localities.  

```{r}
locs_per <- read_csv(here("analysis", "data", "enyalius_locs.csv")) %>% 
  # the variable names are messy
  janitor::clean_names() %>%
  filter(species == "perditus",
    !is.na(latitude), !is.na(longitude),
    # remove duplicates
    !duplicated(latitude),
         # remove localities that are only mapped to a Google Earth municipality. The reserve in the "GPS of the reserve" locality is barely a km, so that is acceptable error relative to the environmental resolution
         source_lat_long != "Google Earth municipality") %>%
  # there are some lat/longs with spaces. Need to fix this
  mutate(longitude = str_remove(longitude, "\\s"), 
         latitude = str_remove(latitude, "\\s")) %>% 
  # convert to numeric
  mutate(longitude = as.numeric(longitude),
         latitude = as.numeric(latitude)) %>% 
  # convert to sf for spatial operations
  st_as_sf(coords = c("longitude", "latitude"),
           crs = 4326,
           remove = FALSE)

# plot localities
plot(st_geometry(af))
plot(st_geometry(locs_per), add = TRUE)
```

Spatial thin. I'm using a 5 km buffer   

```{r}
set.seed(111733)

#run spthin algorithm. This returns 100 possible combinations of removed localities
output <-
  spThin::thin(
    locs_per,
    'latitude',
    'longitude',
    'species',
    thin.par = 5,
    reps = 100,
    locs.thinned.list.return = TRUE,
    write.files = FALSE,
    verbose = FALSE
  )

# I want to maximize the # of localities returned  
maxThin <- which(sapply(output, nrow) == max(sapply(output, nrow)))

# if there are multiple iterations with the max # of localities, pick one
maxThin <-
  output[[ifelse(length(maxThin) > 1, maxThin[1], maxThin)]]

# subset locs to match only thinned locs
locs_per <- locs_per[as.numeric(rownames(maxThin)), ]

# get the unused locs as a testing data set
# this probably isn't useful since they will overlap heavily with the training data, but seems like another piece of info to look at
test_per <- locs_per[-as.numeric(rownames(maxThin)), ]

plot(st_geometry(af))
plot(st_geometry(locs_per), add=TRUE)
```

Write thinned localities to file  

```{r, eval=FALSE}
# Write to file
st_write(locs_per, here("analysis", "output", "thinned_localities", "perditus_thinned.geojson"),
         delete_dsn = TRUE)
```

#### Crop environment

First, I need to read in the environmental data.  

```{r}
bioclims <- terra::rast(here("analysis", "output", "cropped_predictors", "bioclims.tif"))
forest_cover <- terra::rast(here("analysis", "output", "cropped_predictors", "forest_cover.tif"))
```


Cropping and combining variables for analysis.  

```{r, warning=FALSE, message=FALSE}
mcp_per <- st_convex_hull(st_union(locs_per)) %>%
  st_buffer(dist = 0.5) %>% 
  terra::vect()

bioclims_per <- bioclims %>%
  # the bioclims are in a slightly different CRS
  terra::project(forest_cover) %>% 
  terra::crop(mcp_per) %>% 
  terra::mask(mcp_per)

forest_cover_per <- forest_cover %>% 
  terra::crop(bioclims_per) %>% 
  terra::mask(bioclims_per[[1:3]]) 

plot(bioclims_per[[1]])
plot(st_geometry(locs_per), add = TRUE)
plot(forest_cover_per[[1]])
plot(st_geometry(locs_per), add = TRUE)

predictors_per <- c(bioclims_per, forest_cover_per)
```


#### Predictor correlation

Sample 10000 background points.  

```{r}
set.seed(86784)

# for variable correlations
bg_envt_per <- terra::spatSample(predictors_per, 10000, 
                               warn=TRUE, 
                               na.rm = TRUE, 
                               as.df = TRUE,
                               xy = TRUE)

# for use in ENMevaluate
bg_coords_per <- bg_envt_per[,c("x", "y")]
```

Next, I'll extract the values for the localities and calculate the correlations among variables.  

```{r}
# extract values
bg_corr_per <- bg_envt_per %>% select(-x, -y)

# correlation dataframe
corr_df_per <- corrr::correlate(bg_corr_per, method = "pearson") 

# only retain correlations >= 0.75 for visualizing and deciding which to remove
corr_df_75_per <- corr_df_per %>% 
  # replace NAs first
  mutate(across(everything(), 
                ~replace_na(., 0)),
         # take absolute value of all values to make filtering easier. I'm not interested in the direction 
         across(where(is.numeric), abs)) %>% 
  # only keep values 
  mutate(across(everything(),
                ~ ifelse(. < 0.75, 0, .)))

corrr::rplot(corr_df_75_per)
```

I'm prioritizing measures of climate extremes and environmental variability over averages to incorporate information about ecological limits rather than averages. In terms of bioclims, this comes out to BIO4 (temperature seasonality), BIO5 (max temp of the warmest month), BIO6 (min temp of the coldest month), BIO7 (annual temp range), BIO13 (prec of the wettest month), BIO14 (prec of the driest month), BIO15 (prec seasonality).  
None of the forest cover variables are correlated with anything else.  

Variable: what the variable is correlated with.  
**BIO4**: Nothing  
*X* **BIO5**: BIO1, **BIO6**, BIO8, BIO9, BIO10, BIO11  
**BIO6**: BIO1, **BIO5**, BIO8, BIO9, BIO10, BIO11  
**BIO7**: BIO2
**BIO13**: BIO16  
**BIO14**: **BIO15**, BIO17, BIO19  
*X* **BIO15**: **BIO14**, BIO17, BIO19  

BIO5 is correlated with BIO6 and BIO6 (min temp coldest month) is more likely to limit the distribution of lizards in general, so I'm omitting BIO5 from consideration.  
BIO15 (prec seasonality) is a tough variable to model and it's correlated with BIO14, so I'm omitting it from consideration.  

The final variable list:
BIO4, BIO6, BIO7, BIO13, BIO14, forest cover (3 vars)  

```{r}
predictors_per <- predictors_per[[c("bio_04", "bio_06", "bio_07", "bio_13", "bio_14",  "fc_02_evergreen_broadleaf", "fc_03_deciduous_broadleaf", "fc_04_mixed")]]
```


#### Maxent model

I'm using a jackknife model evaluation approach since I only have 17 observations. 

```{r}
set.seed(4567717)
coords_per <- st_coordinates(locs_per)
colnames(coords_per) <- c("x", "y")

folds_per <- ENMeval::get.jackknife(occ = coords_per, 
                            bg = bg_coords_per)
```


Run the model. Predictions are clamped to prevent extrapolation.      

```{r, eval=FALSE}
set.seed(97697)

# the vector of regularization multipliers to test
rms <- seq(0.5, 5, 0.5)

# convert the terra object to a raster stack for use in EMNeval
predictors_per_stack <- raster::stack(predictors_per)

# iterate model building over all chosen parameter settings
sdm_per <-
  ENMeval::ENMevaluate(
    occs = coords_per,
    envs = predictors_per_stack,
    bg.coords = bg_coords_per,
    RMvalues = rms,
    fc = c('L', 'LQ', 'H', 'LQH'),
    # clamping to prevent model extrapolation
    doClamp = TRUE,
    taxon.name = "perditus",
    partitions = "user",
    # going to do a separate run with the final model on testing data
    #occs.testing = test_per,
    user.grp = folds_per,
    clamp = TRUE,
    algorithm = "maxent.jar",
    parallel = TRUE,
    numCores = 6
  )
```

```{r, eval=FALSE}
# write the model to file
write_rds(sdm_per, here("analysis", "output", "sdm_models", "sdm_perditus.rds"))
```

```{r, echo=FALSE}
sdm_per <- read_rds(here("analysis", "output", "sdm_models", "sdm_perditus.rds"))
```

##### Model evaluation

Let's take a look at the model results.  
```{r}
eval_table_per <- sdm_per@results
eval_mods_per <- sdm_per@models

names(eval_mods_per) <-
  str_replace_all(names(eval_mods_per), "\\.", "\\_")
```

Select the final model. First I'm looking at plots of model evaluation stats to get an idea of the spread of stats.  

```{r}
daic_per <- ggplot(data = eval_table_per, aes(x = rm, y = delta.AICc, color = fc)) +
  geom_point() +
  scale_color_viridis_d() +
  theme_bw()

or_per <- ggplot(data = eval_table_per, aes(x = rm, y = or.10p.avg, color = fc)) +
  geom_point() +
  scale_color_viridis_d() +
  theme_bw()

dauc_per <- ggplot(data = eval_table_per, aes(x = rm, y = auc.diff.avg, color = fc)) +
  geom_point() +
  scale_color_viridis_d() +
  theme_bw()

cbi_per <- ggplot(data = eval_table_per, aes(x = rm, y = cbi.val.avg, color = fc)) +
  geom_point() +
  scale_color_viridis_d() +
  theme_bw()

(daic_per + or_per) / (dauc_per + cbi_per)
```

Now I'm going to take a look at tables of delta AICc, omission rate, and AUC to see how close the models are. The model with the lowest AICc has a relatively high omission error rate (0.24), so I chose the model with a lower OR (0.12) that is only 1.15 AICc away (fc LQ and rm 3.5). It is also a simpler model with a 3.5 regularization multiplier, which is nice.  

```{r}
eval_table_per %>% 
  select(delta.AICc, AICc, or.10p.avg, auc.diff.avg, auc.val.avg, rm, fc) %>%
  arrange(delta.AICc) %>% 
  head(10) %>% 
  knitr::kable()
```

Select model.  

```{r}
mod_per <- eval_mods_per$rm_3_5_fc_LQ
opt_seq_tune_per <- eval_table_per$tune.args[eval_table_per$tune.args == "rm.3.5_fc.LQ"]
```

Variable importance. It looks like forests are important again!  

```{r}
plot(mod_per)
```

Plot the response curves. fc_02 is positively related with presence, while fc_04 is negatively related

```{r}
dismo::response(mod_per)
```


##### Project

I'm projecting the model to the study area extent.  
```{r}
pred_per <- ENMeval::eval.predictions(sdm_per)[[opt_seq_tune_per]]
plot(pred_per)
plot(st_geometry(af), add = TRUE)
plot(st_geometry(locs_per), pch = 21, bg = alpha("lightgray", 0.5), add = TRUE)
```



### E. iheringii
Reading in data for plotting.  

```{r}
# atlantic forest shapefile
af <- read_sf(here("analysis", "data", "atlantic_forest", "atlantic_forest.geojson"))
```


#### Spatial thin

Read and filter localities.  

```{r}
locs_ihe <- read_csv(here("analysis", "data", "enyalius_locs.csv")) %>% 
  # the variable names are messy
  janitor::clean_names() %>%
  filter(species == "iheringii",
    !is.na(latitude), !is.na(longitude),
    # remove duplicates
    !duplicated(latitude),
         # remove localities that are only mapped to a Google Earth municipality. The reserve in the "GPS of the reserve" locality is barely a km, so that is acceptable error relative to the environmental resolution
         source_lat_long != "Google Earth municipality") %>%
  # there are some lat/longs with spaces. Need to fix this
  mutate(longitude = str_remove(longitude, "\\s"), 
         latitude = str_remove(latitude, "\\s")) %>% 
  # convert to numeric
  mutate(longitude = as.numeric(longitude),
         latitude = as.numeric(latitude)) %>% 
  # convert to sf for spatial operations
  st_as_sf(coords = c("longitude", "latitude"),
           crs = 4326,
           remove = FALSE)

# plot localities
plot(st_geometry(af))
plot(st_geometry(locs_ihe), add = TRUE)
```

Spatial thin. I'm using a 5 km buffer   

```{r}
set.seed(1333333)

#run spthin algorithm. This returns 100 possible combinations of removed localities
output <-
  spThin::thin(
    locs_ihe,
    'latitude',
    'longitude',
    'species',
    thin.par = 5,
    reps = 100,
    locs.thinned.list.return = TRUE,
    write.files = FALSE,
    verbose = FALSE
  )

# I want to maximize the # of localities returned  
maxThin <- which(sapply(output, nrow) == max(sapply(output, nrow)))

# if there are multiple iterations with the max # of localities, pick one
maxThin <-
  output[[ifelse(length(maxThin) > 1, maxThin[1], maxThin)]]

# subset locs to match only thinned locs
locs_ihe <- locs_ihe[as.numeric(rownames(maxThin)), ]

# get the unused locs as a testing data set
# this probably isn't useful since they will overlap heavily with the training data, but seems like another piece of info to look at
test_ihe <- locs_ihe[-as.numeric(rownames(maxThin)), ]

plot(st_geometry(af))
plot(st_geometry(locs_ihe), add=TRUE)
```

Write thinned localities to file  

```{r, eval=FALSE}
# Write to file
st_write(locs_ihe, here("analysis", "output", "thinned_localities", "perditus_thinned.geojson"),
         delete_dsn = TRUE)
```

#### Crop environment

First, I need to read in the environmental data.  

```{r}
bioclims <- terra::rast(here("analysis", "output", "cropped_predictors", "bioclims.tif"))
forest_cover <- terra::rast(here("analysis", "output", "cropped_predictors", "forest_cover.tif"))
```


Cropping and combining variables for analysis.  

```{r, warning=FALSE, message=FALSE}
mcp_ihe <- st_convex_hull(st_union(locs_ihe)) %>%
  st_buffer(dist = 0.5) %>% 
  terra::vect()

bioclims_ihe <- bioclims %>%
  # the bioclims are in a slightly different CRS
  terra::project(forest_cover) %>% 
  terra::crop(mcp_ihe) %>% 
  terra::mask(mcp_ihe)

forest_cover_ihe <- forest_cover %>% 
  terra::crop(bioclims_ihe) %>% 
  terra::mask(bioclims_ihe[[1:3]]) 

plot(bioclims_ihe[[1]])
plot(st_geometry(locs_ihe), add = TRUE)
plot(forest_cover_ihe[[1]])
plot(st_geometry(locs_ihe), add = TRUE)

predictors_ihe <- c(bioclims_ihe, forest_cover_ihe)
```


#### Predictor correlation

Sample 10000 background points.  

```{r}
set.seed(7457684)

# for variable correlations
bg_envt_ihe <- terra::spatSample(predictors_ihe, 10000, 
                               warn=TRUE, 
                               na.rm = TRUE, 
                               as.df = TRUE,
                               xy = TRUE)

# for use in ENMevaluate
bg_coords_ihe <- bg_envt_ihe[,c("x", "y")]
```

Next, I'll extract the values for the localities and calculate the correlations among variables.  

```{r}
# extract values
bg_corr_ihe <- bg_envt_ihe %>% select(-x, -y)

# correlation dataframe
corr_df_ihe <- corrr::correlate(bg_corr_ihe, method = "pearson") 

# only retain correlations >= 0.75 for visualizing and deciding which to remove
corr_df_75_ihe <- corr_df_ihe %>% 
  # replace NAs first
  mutate(across(everything(), 
                ~replace_na(., 0)),
         # take absolute value of all values to make filtering easier. I'm not interested in the direction 
         across(where(is.numeric), abs)) %>% 
  # only keep values 
  mutate(across(everything(),
                ~ ifelse(. < 0.75, 0, .)))

corrr::rplot(corr_df_75_ihe)
```

I'm prioritizing measures of climate extremes and environmental variability over averages to incorporate information about ecological limits rather than averages. In terms of bioclims, this comes out to BIO4 (temperature seasonality), BIO5 (max temp of the warmest month), BIO6 (min temp of the coldest month), BIO7 (annual temp range), BIO13 (prec of the wettest month), BIO14 (prec of the driest month), BIO15 (prec seasonality).  
None of the forest cover variables are correlated with anything else.  

Variable: what the variable is correlated with.  
*X* **BIO4**: BIO3, **BIO14**, **BIO15**, BIO17, BIO19
*X* **BIO5**: BIO1, **BIO6**, BIO8, BIO9, BIO10, BIO11  
**BIO6**: BIO1, **BIO5**, BIO8, BIO9, BIO10, BIO11  , **BIO13**, **BIO15**
**BIO7**: Nothing
**BIO13**:BIO1, **BIO6**, BIO11, **BIO15**, BIO16, BIO18  
**BIO14**: **BIO4**, **BIO15**, BIO17, BIO19  
*X* **BIO15**: **BIO4**, **BIO6**, BIO11, **BIO13**, **BIO14**, BIO17, BIO19  

BIO4 is correlated with BIO14 and BIO15 and is a seasonality variable, which may not be as precise or reliable as a min/max value, so I'm omitting it.  
BIO5 is correlated with BIO6 and BIO6 (min temp coldest month) is more likely to limit the distribution of lizards in general, so I'm omitting BIO5 from consideration.  
Even though the correlation between BIO6 and BIO13 is slightly above the cutoff (r = 0.759), I'm keeping both because they are ecologically important variables and the proximity to the cutoff isn't too distant.  
BIO15 (prec seasonality) is a tough variable to model and it's correlated with four other variables, so I'm omitting it from consideration.  

The final variable list:
BIO6, BIO7, BIO13, BIO14, forest cover (3 vars)  

```{r}
predictors_ihe <- predictors_ihe[[c("bio_06", "bio_07", "bio_13", "bio_14",  "fc_02_evergreen_broadleaf", "fc_03_deciduous_broadleaf", "fc_04_mixed")]]
```


#### Maxent model

I'm using a jackknife model evaluation approach since I only have 25 observations. 

```{r}
set.seed(34444437)
coords_ihe <- st_coordinates(locs_ihe)
colnames(coords_ihe) <- c("x", "y")

folds_ihe <- ENMeval::get.jackknife(occ = coords_ihe, 
                            bg = bg_coords_ihe)
```


Run the model. Predictions are clamped to prevent extrapolation.    

```{r, eval=FALSE}
set.seed(2699997)

# the vector of regularization multipliers to test
rms <- seq(0.5, 5, 0.5)

# convert the terra object to a raster stack for use in EMNeval
predictors_ihe_stack <- raster::stack(predictors_ihe)

# iterate model building over all chosen parameter settings
sdm_ihe <-
  ENMeval::ENMevaluate(
    occs = coords_ihe,
    envs = predictors_ihe_stack,
    bg.coords = bg_coords_ihe,
    RMvalues = rms,
    fc = c('L', 'LQ', 'H', 'LQH'),
    # clamping to prevent model extrapolation
    doClamp = TRUE,
    taxon.name = "iheringii",
    partitions = "user",
    # going to do a separate run with the final model on testing data
    #occs.testing = test_ihe,
    user.grp = folds_ihe,
    clamp = TRUE,
    algorithm = "maxent.jar",
    parallel = TRUE,
    numCores = 6
  )
```

```{r, eval=FALSE}
# write the model to file
write_rds(sdm_ihe, here("analysis", "output", "sdm_models", "sdm_iheringii.rds"))
```

```{r, echo=FALSE}
sdm_ihe <- read_rds(here("analysis", "output", "sdm_models", "sdm_iheringii.rds"))
```

##### Model evaluation

Let's take a look at the model results.  
```{r}
eval_table_ihe <- sdm_ihe@results
eval_mods_ihe <- sdm_ihe@models

names(eval_mods_ihe) <-
  str_replace_all(names(eval_mods_ihe), "\\.", "\\_")
```

Select the final model. First I'm looking at plots of model evaluation stats to get an idea of the spread of stats.  

```{r}
daic_ihe <- ggplot(data = eval_table_ihe, aes(x = rm, y = delta.AICc, color = fc)) +
  geom_point() +
  scale_color_viridis_d() +
  theme_bw()

or_ihe <- ggplot(data = eval_table_ihe, aes(x = rm, y = or.10p.avg, color = fc)) +
  geom_point() +
  scale_color_viridis_d() +
  theme_bw()

dauc_ihe <- ggplot(data = eval_table_ihe, aes(x = rm, y = auc.diff.avg, color = fc)) +
  geom_point() +
  scale_color_viridis_d() +
  theme_bw()

cbi_ihe <- ggplot(data = eval_table_ihe, aes(x = rm, y = cbi.val.avg, color = fc)) +
  geom_point() +
  scale_color_viridis_d() +
  theme_bw()

(daic_ihe + or_ihe) / (dauc_ihe + cbi_ihe)
```

Now I'm going to take a look at tables of delta AICc, omission rate, and AUC to see how close the models are. All of the top models have the same omission rate, similar AUC, and are either LQ or L. I chose the simplest model within 2 AICc of the top model, which was the rm 2.5 and linear feature class model. The top was a rm 2.5 linear quadratic, but even marginally simpler is better within reasonable limits. After skimming through them, they are all very similar models.  

```{r}
eval_table_ihe %>% 
  select(delta.AICc, AICc, or.10p.avg, auc.diff.avg, auc.val.avg, rm, fc) %>%
  arrange(delta.AICc) %>% 
  head(10) %>% 
  knitr::kable()
```

Select model.  

```{r}
mod_ihe <- eval_mods_ihe$rm_2_5_fc_L
opt_seq_tune_ihe <- eval_table_ihe$tune.args[eval_table_ihe$tune.args == "rm.2.5_fc.L"]
```

Variable importance. It looks like bioclims have an influence here!

```{r}
plot(mod_ihe)
```

Plot the response curves. BIO6 is positively related with presence, BIO7 is negatively related, BIO14 is negatively related, fc_02 is positively related, and fc_03 is positively related. It's interesting that BIO14, precipitation of the driest month, is negatively related. I would expect that the lizards don't want it to get as dry, but maybe I'm missing something about their natural history. I'll have to go back an reread the literature I have on them.  
 
```{r}
dismo::response(mod_ihe)
```


##### Project

I'm projecting the model to the study area extent. It's not predicting strong suitability for the southern localities. I'll have to look at the genetic structure and locality info more closely to see what's up with them.   
```{r}
pred_ihe <- ENMeval::eval.predictions(sdm_ihe)[[opt_seq_tune_ihe]]
plot(pred_ihe)
plot(st_geometry(af), add = TRUE)
plot(st_geometry(locs_ihe), pch = 21, bg = alpha("lightgray", 0.5), add = TRUE)
```

